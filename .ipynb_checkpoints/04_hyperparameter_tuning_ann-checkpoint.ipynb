{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c4eb19-34a1-4bfc-a553-e8e722dd15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furka\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from feature_engine.encoding import OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad29b17e-e92f-4a9a-800f-7a89a0edd8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoder and scaler\n",
    "with open('oh_encoder_geo.pkl','rb') as file:\n",
    "    oh_encoder_geo=pickle.load(file)\n",
    "\n",
    "with open('label_encoder_gender.pkl', 'rb') as file:\n",
    "    label_encoder_gender = pickle.load(file)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ac2a19-4fdb-4166-8748-1308430335c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\furka\\JupyterNotebookProjects\\End-to-End-Churn-Modelling-Binary-Classification\\Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e425fa-31e8-495b-be0d-5c2360e86b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the unnecessary columns\n",
    "df=df.drop(['RowNumber','CustomerId','Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9e64ab-c8f1-4bc2-bf82-098a7ae1c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows containing missing data and duplicate data were deleted.\n"
     ]
    }
   ],
   "source": [
    "# Drop the null values.\n",
    "# Since the number of missing data is low, we can directly delete the missing data instead of filling it in. \n",
    "# Because it will not affect the model. We can use dropna() for this.\n",
    "df = df.dropna()\n",
    "# Dropping the duplicate values\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print('Rows containing missing data and duplicate data were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c69fb2-e638-41fe-abdd-070bb4050e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset separate dataset into train and test successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate into train and test set\n",
    "# Remember to set the seed (random_state for this sklearn function)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['Exited'], axis=1), # predictive variables\n",
    "    df['Exited'], # target\n",
    "    test_size=0.2, # portion of dataset to allocate to test set\n",
    "    random_state=0, # we are setting the seed here\n",
    ")\n",
    "\n",
    "print('The dataset separate dataset into train and test successfully')\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2e554a-4c47-4275-a4bd-cdcc6fb4861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and Feature Scaling\n",
    "X_train = label_encoder_gender.transform(X_train)\n",
    "X_test = label_encoder_gender.transform(X_test)\n",
    "\n",
    "X_train = oh_encoder_geo.transform(X_train)\n",
    "X_test = oh_encoder_geo.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_train.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71eeeaf8-4e10-4cde-8ac3-600ef67d5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the model with dynamic parameters\n",
    "def create_model(trial):\n",
    "    neurons = trial.suggest_categorical('neurons', [8, 16, 32, 64, 128])\n",
    "    layers = trial.suggest_int('layers', 1, 3)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e26f81-a677-4fb6-8360-42717e45bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function\n",
    "def objective(trial):\n",
    "    # Create and compile the model\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Get hyperparameters\n",
    "    epochs = trial.suggest_categorical('epochs', [50, 100])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])\n",
    "    \n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # K-Fold cross-validation\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_score = model.evaluate(X_val, y_val, verbose=0)[1]  # Get accuracy\n",
    "        scores.append(val_score)\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6fce273-5d7e-41fb-8a21-613f739112c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-03 21:59:19,749] A new study created in memory with name: no-name-a9d75a9e-7cbb-44f1-ab6b-abbb1e3f8d3b\n",
      "[I 2024-11-03 21:59:47,949] Trial 1 finished with value: 0.7956252296765646 and parameters: {'neurons': 16, 'layers': 3, 'learning_rate': 1.2477923824405202e-05, 'epochs': 50, 'batch_size': 64}. Best is trial 1 with value: 0.7956252296765646.\n",
      "[I 2024-11-03 22:00:07,891] Trial 7 finished with value: 0.7973750034968058 and parameters: {'neurons': 8, 'layers': 3, 'learning_rate': 4.655427676519257e-05, 'epochs': 50, 'batch_size': 16}. Best is trial 7 with value: 0.7973750034968058.\n",
      "[I 2024-11-03 22:00:19,089] Trial 8 finished with value: 0.7968751589457194 and parameters: {'neurons': 16, 'layers': 1, 'learning_rate': 1.2882176570689467e-05, 'epochs': 100, 'batch_size': 64}. Best is trial 7 with value: 0.7973750034968058.\n",
      "[I 2024-11-03 22:00:26,603] Trial 9 finished with value: 0.8663754463195801 and parameters: {'neurons': 16, 'layers': 3, 'learning_rate': 0.004957239331389894, 'epochs': 100, 'batch_size': 64}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:28,969] Trial 4 finished with value: 0.8628746072451273 and parameters: {'neurons': 64, 'layers': 1, 'learning_rate': 0.0005359603568739183, 'epochs': 50, 'batch_size': 16}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:30,681] Trial 3 finished with value: 0.8128750721613566 and parameters: {'neurons': 32, 'layers': 1, 'learning_rate': 1.9990853064178626e-05, 'epochs': 50, 'batch_size': 32}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:34,819] Trial 6 finished with value: 0.8597501317660013 and parameters: {'neurons': 128, 'layers': 1, 'learning_rate': 0.00018090792956389535, 'epochs': 100, 'batch_size': 16}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:45,184] Trial 10 finished with value: 0.8022499680519104 and parameters: {'neurons': 8, 'layers': 2, 'learning_rate': 6.424227473734962e-05, 'epochs': 50, 'batch_size': 32}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:47,756] Trial 5 finished with value: 0.8586252331733704 and parameters: {'neurons': 64, 'layers': 3, 'learning_rate': 0.0047314234785675565, 'epochs': 50, 'batch_size': 8}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:00:52,209] Trial 11 finished with value: 0.8628746072451273 and parameters: {'neurons': 8, 'layers': 3, 'learning_rate': 0.0008470731555563536, 'epochs': 100, 'batch_size': 64}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:01:37,568] Trial 2 finished with value: 0.8492497007052103 and parameters: {'neurons': 16, 'layers': 3, 'learning_rate': 6.064244951391239e-05, 'epochs': 100, 'batch_size': 16}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:01:48,067] Trial 15 finished with value: 0.8658752838770548 and parameters: {'neurons': 64, 'layers': 3, 'learning_rate': 4.1299728111968984e-05, 'epochs': 100, 'batch_size': 32}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:02:17,420] Trial 0 finished with value: 0.8619996309280396 and parameters: {'neurons': 64, 'layers': 1, 'learning_rate': 0.00012457219576664537, 'epochs': 100, 'batch_size': 8}. Best is trial 9 with value: 0.8663754463195801.\n",
      "[I 2024-11-03 22:02:17,868] Trial 19 finished with value: 0.8696255882581075 and parameters: {'neurons': 64, 'layers': 2, 'learning_rate': 0.0033317500419554674, 'epochs': 100, 'batch_size': 32}. Best is trial 19 with value: 0.8696255882581075.\n",
      "[I 2024-11-03 22:02:20,545] Trial 13 finished with value: 0.8701252937316895 and parameters: {'neurons': 64, 'layers': 3, 'learning_rate': 0.004711114861577694, 'epochs': 50, 'batch_size': 8}. Best is trial 13 with value: 0.8701252937316895.\n",
      "[I 2024-11-03 22:02:26,708] Trial 12 finished with value: 0.8473747173945109 and parameters: {'neurons': 8, 'layers': 3, 'learning_rate': 0.0003334397068903444, 'epochs': 50, 'batch_size': 8}. Best is trial 13 with value: 0.8701252937316895.\n",
      "[I 2024-11-03 22:02:34,904] Trial 17 finished with value: 0.8624990185101827 and parameters: {'neurons': 16, 'layers': 2, 'learning_rate': 0.009399918635991588, 'epochs': 100, 'batch_size': 8}. Best is trial 13 with value: 0.8701252937316895.\n",
      "[I 2024-11-03 22:02:35,607] Trial 16 finished with value: 0.8622497717539469 and parameters: {'neurons': 32, 'layers': 1, 'learning_rate': 0.0019976763058638406, 'epochs': 50, 'batch_size': 8}. Best is trial 13 with value: 0.8701252937316895.\n",
      "[I 2024-11-03 22:02:45,639] Trial 18 finished with value: 0.8631247679392496 and parameters: {'neurons': 64, 'layers': 2, 'learning_rate': 0.008097162395198849, 'epochs': 100, 'batch_size': 8}. Best is trial 13 with value: 0.8701252937316895.\n",
      "[I 2024-11-03 22:02:46,707] Trial 14 finished with value: 0.8705002466837565 and parameters: {'neurons': 128, 'layers': 3, 'learning_rate': 2.7745708726617632e-05, 'epochs': 100, 'batch_size': 8}. Best is trial 14 with value: 0.8705002466837565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'neurons': 128, 'layers': 3, 'learning_rate': 2.7745708726617632e-05, 'epochs': 100, 'batch_size': 8}\n",
      "Best score:  0.8705002466837565\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20, n_jobs=8)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", study.best_params)\n",
    "print(\"Best score: \", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.12.5)",
   "language": "python",
   "name": "3.12.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
